{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26cd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db06d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = {\n",
    "    'train_data_dir_normal': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\train\\NORMAL\",\n",
    "    'train_data_dir_pneumonia': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\train\\PNEUMONIA\",\n",
    "    'test_data_dir_normal': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\test\\NORMAL\",\n",
    "    'test_data_dir_pneumonia': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\test\\PNEUMONIA\",\n",
    "    'data_val_dir_normal': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\val\\NORMAL\",\n",
    "    'data_val_dir_pneumonia': r\"C:\\Users\\beher\\OneDrive\\Desktop\\seminar\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\X-AI-assisted-deep-learning-methods-to-detect-pneumonia-main\\chest_xray\\val\\PNEUMONIA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d70336",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in path_dict.items():\n",
    "    path_dict[key] = pathlib.Path(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2731c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b888d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new image size (e.g., 128x128 pixels)\n",
    "new_image_size = (128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70659d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in path_dict.items():\n",
    "    images = list(path_dict[key].glob('*.jpeg'))\n",
    "    for img in images:\n",
    "        image = cv2.imread(str(img))\n",
    "        resized_img = cv2.resize(image, new_image_size)  # Resize to the new size\n",
    "        X.append(resized_img)\n",
    "        if 'normal' in key:\n",
    "            y.append(0)  # 0 - normal\n",
    "        else:\n",
    "            y.append(1)  # 1 - pneumonia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f86d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39516538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8784, 128, 128, 3), (2928, 128, 128, 3), (8784,), (2928,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d74c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0470e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596a7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beher\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Create an AlexNet-based model\n",
    "model = keras.Sequential([\n",
    "    Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=new_image_size + (3,)),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    \n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd54d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa633ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added EarlyStopping callback to stop training if validation loss doesn't improve for 10 epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b104f99e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.61 GiB for an array with shape (8784, 128, 128, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optree\\ops.py:594\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    592\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    593\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.61 GiB for an array with shape (8784, 128, 128, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=30, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab97e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd467cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary values\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "y_test_binary = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "precision = precision_score(y_test_binary, y_pred_binary)\n",
    "recall = recall_score(y_test_binary, y_pred_binary)\n",
    "f1 = f1_score(y_test_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test_binary, y_pred[:, 1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b55d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve (AUC={roc_auc:.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=500, height=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88fc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a61811",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = np.argmax(y_pred, axis=1)\n",
    "y_test_scaled = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85532f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test_scaled, y_pred_scaled)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e26b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_image(image, index, true_label):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    explanation = explainer.explain_instance(image.astype('double'), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "    \n",
    "    # Create a figure with 2 rows and 5 columns\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 8))\n",
    "\n",
    "    # Display the original image\n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].set_title('Original Image (True Label: {})'.format(true_label))\n",
    "\n",
    "    # Display the LIME mask with color representation and labels\n",
    "    cmap = 'viridis'\n",
    "    mask_image = axs[0, 1].imshow(mask, cmap=cmap, alpha=0.5)\n",
    "    axs[0, 1].set_title(\"LIME Mask - {}\".format('Normal' if y_pred_scaled[index] == 0 else 'Pneumonia'))\n",
    "    colorbar = plt.colorbar(mask_image, ax=axs[0, 1])\n",
    "    colorbar.set_label('Importance')\n",
    "    \n",
    "    # Add legend to the mask image\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label='Supports Prediction', markerfacecolor='yellow', markersize=10),\n",
    "                       Line2D([0], [0], marker='o', color='w', label='Against Prediction', markerfacecolor='violet', markersize=10)]\n",
    "    axs[0, 1].legend(handles=legend_elements, loc='lower left')\n",
    "    \n",
    "    \n",
    "    # Display the combined image with boundaries\n",
    "    axs[0, 2].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    axs[0, 2].set_title('Predicted - ' + str('Normal' if y_pred_scaled[index] == 0 else 'Pneumonia') + '\\n Ground Truth - ' + str('Normal' if y_test_scaled[index] == 0 else 'Pneumonia')\n",
    "             + ' \\n Green Regions -> Supporting the predicted label \\n Red Regions -> Against the predicted label')\n",
    "    \n",
    "    # Display the superpixel regions with numbers\n",
    "    superpixel_regions = explanation.segments\n",
    "    axs[1, 0].imshow(superpixel_regions, cmap='viridis')\n",
    "    axs[1, 0].set_title('Superpixel Regions with Numbers')\n",
    "    \n",
    "    for segment_num in np.unique(superpixel_regions):\n",
    "        y, x = np.where(superpixel_regions == segment_num)\n",
    "        axs[1, 0].text(np.mean(x), np.mean(y), str(segment_num), color='black', ha='center', va='center', fontsize=8)\n",
    "\n",
    "    # Generate a bar plot for features and their weights\n",
    "    features_normal = [f[0] for f in explanation.local_exp[0] if f[1] > 0]  # Only positive contributions\n",
    "    weights_normal = [f[1] for f in explanation.local_exp[0] if f[1] > 0]\n",
    "\n",
    "    features_pneumonia = [f[0] for f in explanation.local_exp[1] if f[1] > 0]  # Only positive contributions\n",
    "    weights_pneumonia = [f[1] for f in explanation.local_exp[1] if f[1] > 0]\n",
    "\n",
    "    axs[1, 1].barh(features_normal, weights_normal, color='skyblue', label='Normal')\n",
    "    axs[1, 1].barh(features_pneumonia, weights_pneumonia, color='orange', label='Pneumonia')\n",
    "    axs[1, 1].set_xlabel('Weight')\n",
    "    axs[1, 1].set_title('Feature Importance')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return explanation\n",
    "\n",
    "# Assuming you have model, X_test_scaled, y_pred_scaled, and y_test_scaled defined\n",
    "for index, img in enumerate(X_test_scaled[:10]):\n",
    "    true_label = 'Normal' if y_test_scaled[index] == 0 else 'Pneumonia'\n",
    "    explain_image(img, index, true_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_image(image):\n",
    "    # Add random noise to the image\n",
    "    perturbed_image = image + np.random.normal(0, 0.1, image.shape)\n",
    "    return perturbed_image\n",
    "\n",
    "def explain_image(image, index, true_label):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    \n",
    "    # Create a single perturbed image using perturb_image function\n",
    "    perturbed_image = perturb_image(image)\n",
    "    \n",
    "    # Use explain_instance with the perturbed image\n",
    "    explanation = explainer.explain_instance(\n",
    "        perturbed_image.astype('double'), \n",
    "        model.predict, \n",
    "        top_labels=5, \n",
    "        hide_color=0, \n",
    "        num_samples=1000,\n",
    "        num_features=10  # Adjust the number of features as needed\n",
    "    )\n",
    "    \n",
    "    # Rest of the code remains unchanged...\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a figure with 2 rows and 5 columns\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 8))\n",
    "\n",
    "    # Display the original image\n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].set_title('Original Image (True Label: {})'.format(true_label))\n",
    "\n",
    "    # Display the LIME mask with color representation and labels\n",
    "    cmap = 'viridis'\n",
    "    mask_image = axs[0, 1].imshow(explanation.segments, cmap=cmap, alpha=0.5)\n",
    "    axs[0, 1].set_title(\"LIME Mask - {}\".format('Normal' if y_pred_scaled[index] == 0 else 'Pneumonia'))\n",
    "    colorbar = plt.colorbar(mask_image, ax=axs[0, 1])\n",
    "    colorbar.set_label('Importance')\n",
    "    \n",
    "    # Add legend to the mask image\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label='Supports Prediction', markerfacecolor='yellow', markersize=10),\n",
    "                       Line2D([0], [0], marker='o', color='w', label='Against Prediction', markerfacecolor='violet', markersize=10)]\n",
    "    axs[0, 1].legend(handles=legend_elements, loc='lower left')\n",
    "    \n",
    "    # Display the combined image with boundaries\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "    axs[0, 2].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    axs[0, 2].set_title('Predicted - ' + str('Normal' if y_pred_scaled[index] == 0 else 'Pneumonia') + '\\n Ground Truth - ' + str('Normal' if y_test_scaled[index] == 0 else 'Pneumonia')\n",
    "             + ' \\n Green Regions -> Supporting the predicted label \\n Red Regions -> Against the predicted label')\n",
    "    \n",
    "    # Display the superpixel regions with numbers\n",
    "    superpixel_regions = explanation.segments\n",
    "    axs[1, 0].imshow(superpixel_regions, cmap='viridis')\n",
    "    axs[1, 0].set_title('Superpixel Regions with Numbers')\n",
    "    \n",
    "    for segment_num in np.unique(superpixel_regions):\n",
    "        y, x = np.where(superpixel_regions == segment_num)\n",
    "        axs[1, 0].text(np.mean(x), np.mean(y), str(segment_num), color='black', ha='center', va='center', fontsize=8)\n",
    "\n",
    "    # Generate a bar plot for features and their weights\n",
    "    features_normal = [f[0] for f in explanation.local_exp[0] if f[1] > 0]  # Only positive contributions\n",
    "    weights_normal = [f[1] for f in explanation.local_exp[0] if f[1] > 0]\n",
    "\n",
    "    features_pneumonia = [f[0] for f in explanation.local_exp[1] if f[1] > 0]  # Only positive contributions\n",
    "    weights_pneumonia = [f[1] for f in explanation.local_exp[1] if f[1] > 0]\n",
    "\n",
    "    axs[1, 1].barh(features_normal, weights_normal, color='skyblue', label='Normal')\n",
    "    axs[1, 1].barh(features_pneumonia, weights_pneumonia, color='orange', label='Pneumonia')\n",
    "    axs[1, 1].set_xlabel('Weight')\n",
    "    axs[1, 1].set_title('Feature Importance')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return explanation\n",
    "    \n",
    "    # Assuming you have model, X_test_scaled, y_pred_scaled, and y_test_scaled defined\n",
    "for index, img in enumerate(X_test_scaled[:10]):\n",
    "    true_label = 'Normal' if y_test_scaled[index] == 0 else 'Pneumonia'\n",
    "    explain_image(img, index, true_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
